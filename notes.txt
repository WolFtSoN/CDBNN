Log:
-----------------------------------------
23.2.2025:
-----------------------------------------
What we checked:
for a specific chip, bank UDIMM (SK-Hynix)
1) Subarray boundries
2) Maj3-5-9 success rates - for random patterns.
    2.1) Including optimal timing parameters
3) Multi-Row-Copy - 100% works for up to 2,4 rows
    3.1) Including optimal timing parameters
--------
What we want to know in order to start using as compute resource:
1) Optimal computation row:
    1.1) can perform MAJ3 almost perfectly - minimum error probability
    1.2) can copy into it almost perfectly - minimum error on copy, zero probability to override a different row. I.e. row copy is exact
    1.3) Optimal timing parameters for each basic operation
2) Optimal frac location
3) AND / OR - find optimum place for 0 / 1 operands
4) Sub-array parallelism (many sub arrays)
-----------------------------------------
25.2.2025
-----------------------------------------
We've found out several problems:
-MAJ3 with 12 rows test had a bug (pattern had 3 frac rows, but no frac operation was used) - we can't use the results obtained.
-When tested manually the best rows for MAJ3 with 4 rows we observed:
--When using 1st row as FRAC, it seemed that output always goes like the "strong row" i.e. R1.
--When using R1 as FRAC, it seemed that output favored 1. We tried the following to no clear conclusion:
---Start R1 as 0 before appkying FRAC
---Playing with FRAC params (t_frac, n_frac) 
----for t_frac 0 (like the test), n_frac didn't have effect
----for t_frac 1, n_frac did have effect, though the change observed didn't make sense
--We might want to retest this in a more orderly way
-When tested manually the best rows for MAJ3 with 16 rows we observed:
--Similar, even more confusing behavior to 4 rows
---Shockingly, R1 was more dominant even than the rest of the 14 compute rows.

Possible debug routes/problems we thought off:
1. We don't interpret the test results correctly, or the test isn't comprehensive enough
2. FRAC operation don't work properly

We want to check this out tommorow.
-----------------------------------------
26.2.2025
-----------------------------------------
Good progress with yesterday's problems.
We found out several bugs in our scripts, mainly:
1. Wrong bank id used in our manual check (MAJ3 dir)
2. We cross tested for different t12, t23 for rows that didn't support such timings

Results are much better and in line with manual testing. 
We still suspect FRAC parameters might be suboptimal, as MAJ3 using 6,12 rows is far superior to 8,16 rows

-----------------------------------------
4.3.2025
-----------------------------------------
We've found out not every pair of rows R1 R2 can participate in RowCopy.
We hypothesize this is due to the hierirchical row decoder design Ismail talks about in PULSAR
(They do infact open, but other rows open as well)

We verfied this is the case by trying t12 = 10, t23 = [0,..,10] - no new pairs of rows approached
 - Interestingly, not all pairs support the same timing params. No additional rows are opened for t23 > 4

We found out manually and some simple graph analysis (see FunctionalRowCopy directory) that we still can connect many rows into
our desired computation rows (best that were found in testing), using a small amount of "routing rows"

We currently use:
 - 24 as a gate into 152, 408
 - 25 as a gate into 153, 409
 - 536 as a gate into 664, 665
 - 24 is connceted to 25, and 536

Thus, every row that is connected to either 24, 25, or 536 can be connceted to all of the computation rows

Compute rows fill was changed - instead of ABCABC as Ismail tested, we preferred either AABBCC or ABABCC
to allow 2-row activation between rows of the same value (say A and A).
Reteseting with these patterns, we've seen error rates varies slightly (99.7% ABABCC, ~96% AABBCC).
Hence we've chosen the better ABABCC.

We then implemnted a 3x3 BNN using DRAM Bender. No error where observed (though we did not test this throughly)


-----------------------------------------
15.03.2025
-----------------------------------------
We need to answer these 3 following questions:
1. Check that our imem after enlargement fits all the instructions
2. Check if we can make a coe file in Vivado and initialize the DIMM with bypassing the PCIE 
3. Does using coe is equivalent to flahsing through the PCIE, and does the DRAM will work as expected after reseting

-----------------------------------------
19.03.2025
-----------------------------------------
1. The RowCopy works both ways
2. API change to "execute" function

What's left:
    1. To finish debugging power of 3 networks 
    2. Add padding for networks that not power of 3 
    3. Time analysis:
        1. Minimize precharge and SLEEP timings
        2. Approximate the timings for PCIE and the writing the inputs into the DRAM
        3. Calculate the timings we readback to the CPU for inverse the new X data 

    4. Get ACT-PRE txt file -> for VAMPIRE
    5. CPU computations -> MAJ(MAJ) from several subarrays
    6. MAJ(MAJ) in the last layer 
    7. Bit flips 

-----------------------------------------
20.03.2025
-----------------------------------------
Done:
    1. The network works for every power of 3 size inputs
    2. Add padding for networks that not power of 3
    3. Add batches 
